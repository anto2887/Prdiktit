# backend/app/services/analytics_service.py
"""
Analytics Service - Handles personal analytics, group heatmaps, and prediction patterns
"""

import logging
from datetime import datetime, timezone
from typing import List, Dict, Optional
from collections import defaultdict, Counter
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, case

from ..db.models import (
    UserAnalytics, UserPrediction, Fixture, User, Group, 
    GroupHeatmap, UserStreak, PredictionStatus, MatchStatus
)
from ..db.repository import get_group_members
from ..services.cache_service import RedisCache

logger = logging.getLogger(__name__)

class AnalyticsService:
    """Handles all analytics calculations and caching"""
    
    def __init__(self, db: Session, cache: Optional[RedisCache] = None):
        self.db = db
        self.cache = cache
        self.activation_week = 5  # Analytics activate at week 5
    
    async def calculate_user_analytics(self, user_id: int, season: str, current_week: int) -> Dict:
        """Calculate comprehensive user analytics"""
        
        if current_week < self.activation_week:
            logger.info(f"Analytics not yet available - current week {current_week} < activation week {self.activation_week}")
            return {'analytics_available': False, 'activation_week': self.activation_week}
        
        logger.info(f"üìä Calculating analytics for user {user_id}, season {season}")
        
        try:
            # Check cache first
            cache_key = f"user_analytics:{user_id}:{season}:{current_week}"
            if self.cache:
                cached = await self.cache.get(cache_key)
                if cached:
                    logger.info(f"üìã Returning cached analytics for user {user_id}")
                    return cached
            
            # Calculate analytics
            analytics = {
                'analytics_available': True,
                'user_id': user_id,
                'season': season,
                'current_week': current_week,
                'last_updated': datetime.now(timezone.utc).isoformat()
            }
            
            # Performance trends
            analytics['performance_trends'] = await self._calculate_performance_trends(user_id, season, current_week)
            
            # Strong/weak matchups
            analytics['team_performance'] = await self._analyze_team_performance(user_id, season, current_week)
            
            # Prediction patterns
            analytics['prediction_patterns'] = await self._analyze_prediction_patterns(user_id, season, current_week)
            
            # Streaks
            analytics['streaks'] = await self._calculate_streaks(user_id, season, current_week)
            
            # Overall summary
            analytics['summary'] = await self._generate_summary(user_id, season, current_week)
            
            # Cache the results
            if self.cache:
                await self.cache.set(cache_key, analytics, expiry=3600)  # 1 hour cache
            
            # Store in database for historical tracking
            await self._store_analytics(user_id, 'comprehensive', season, analytics)
            
            logger.info(f"‚úÖ Analytics calculated for user {user_id}")
            return analytics
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating analytics for user {user_id}: {e}")
            raise
    
    async def _calculate_performance_trends(self, user_id: int, season: str, current_week: int) -> Dict:
        """Calculate performance trends over the last 5 weeks"""
        
        # Get weekly performance data
        weekly_data = self.db.query(
            UserPrediction.week,
            func.sum(UserPrediction.points).label('total_points'),
            func.count(UserPrediction.id).label('prediction_count'),
            func.sum(case((UserPrediction.points == 3, 1), else_=0)).label('perfect_predictions'),
            func.sum(case((UserPrediction.points == 1, 1), else_=0)).label('correct_results'),
            func.sum(case((UserPrediction.points == 0, 1), else_=0)).label('incorrect_predictions')
        ).filter(
            UserPrediction.user_id == user_id,
            UserPrediction.season == season,
            UserPrediction.week < current_week,
            UserPrediction.prediction_status == PredictionStatus.PROCESSED
        ).group_by(UserPrediction.week).order_by(UserPrediction.week.desc()).limit(5).all()
        
        trends = []
        for week_data in reversed(weekly_data):  # Reverse to get chronological order
            total_preds = week_data.prediction_count
            accuracy = 0
            avg_points = 0
            
            if total_preds > 0:
                correct_preds = week_data.perfect_predictions + week_data.correct_results
                accuracy = round((correct_preds / total_preds) * 100, 1)
                avg_points = round(week_data.total_points / total_preds, 2)
            
            trends.append({
                'week': week_data.week,
                'total_points': week_data.total_points,
                'prediction_count': total_preds,
                'accuracy_percentage': accuracy,
                'average_points': avg_points,
                'perfect_predictions': week_data.perfect_predictions,
                'correct_results': week_data.correct_results,
                'incorrect_predictions': week_data.incorrect_predictions
            })
        
        # Calculate trend direction
        if len(trends) >= 2:
            recent_avg = sum(t['average_points'] for t in trends[-2:]) / 2
            older_avg = sum(t['average_points'] for t in trends[:-2]) / max(1, len(trends) - 2)
            trend_direction = "improving" if recent_avg > older_avg else "declining" if recent_avg < older_avg else "stable"
        else:
            trend_direction = "insufficient_data"
        
        return {
            'weekly_performance': trends,
            'trend_direction': trend_direction,
            'best_week': max(trends, key=lambda x: x['total_points']) if trends else None,
            'worst_week': min(trends, key=lambda x: x['total_points']) if trends else None
        }
    
    async def _analyze_team_performance(self, user_id: int, season: str, current_week: int) -> Dict:
        """Analyze performance against specific teams"""
        
        # Get predictions with fixture data
        team_stats = self.db.query(
            Fixture.home_team,
            Fixture.away_team,
            func.count(UserPrediction.id).label('prediction_count'),
            func.sum(UserPrediction.points).label('total_points'),
            func.avg(UserPrediction.points).label('avg_points')
        ).join(
            UserPrediction, Fixture.fixture_id == UserPrediction.fixture_id
        ).filter(
            UserPrediction.user_id == user_id,
            UserPrediction.season == season,
            UserPrediction.week < current_week,
            UserPrediction.prediction_status == PredictionStatus.PROCESSED
        ).group_by(Fixture.home_team, Fixture.away_team).all()
        
        # Aggregate by individual teams
        team_performance = defaultdict(lambda: {'predictions': 0, 'total_points': 0, 'matches': []})
        
        for stat in team_stats:
            # Count this match for both teams
            for team in [stat.home_team, stat.away_team]:
                team_performance[team]['predictions'] += 1
                team_performance[team]['total_points'] += stat.total_points
                team_performance[team]['matches'].append({
                    'opponent': stat.away_team if team == stat.home_team else stat.home_team,
                    'points': stat.total_points,
                    'avg_points': round(float(stat.avg_points), 2)
                })
        
        # Calculate averages and sort
        team_results = []
        for team, data in team_performance.items():
            if data['predictions'] >= 2:  # Only include teams with 2+ predictions
                avg_points = round(data['total_points'] / data['predictions'], 2)
                team_results.append({
                    'team': team,
                    'prediction_count': data['predictions'],
                    'total_points': data['total_points'],
                    'average_points': avg_points
                })
        
        # Sort by average points
        team_results.sort(key=lambda x: x['average_points'], reverse=True)
        
        return {
            'strongest_teams': team_results[:5],  # Top 5 teams you predict well
            'weakest_teams': team_results[-5:] if len(team_results) > 5 else [],  # Bottom 5
            'total_teams_analyzed': len(team_results)
        }
    
    async def _analyze_prediction_patterns(self, user_id: int, season: str, current_week: int) -> Dict:
        """Analyze prediction patterns and tendencies"""
        
        # Get all processed predictions with fixture data
        predictions = self.db.query(
            UserPrediction.score1,
            UserPrediction.score2,
            UserPrediction.points,
            Fixture.home_team,
            Fixture.away_team,
            Fixture.home_score,
            Fixture.away_score
        ).join(
            Fixture, UserPrediction.fixture_id == Fixture.fixture_id
        ).filter(
            UserPrediction.user_id == user_id,
            UserPrediction.season == season,
            UserPrediction.week < current_week,
            UserPrediction.prediction_status == PredictionStatus.PROCESSED,
            Fixture.status.in_([MatchStatus.FINISHED, MatchStatus.FINISHED_AET, MatchStatus.FINISHED_PEN])
        ).all()
        
        if not predictions:
            return {'insufficient_data': True}
        
        patterns = {
            'home_bias': 0,
            'draw_tendency': 0,
            'high_scoring_tendency': 0,
            'conservative_tendency': 0,
            'over_optimistic': 0,
            'under_pessimistic': 0
        }
        
        total_predictions = len(predictions)
        
        for pred in predictions:
            pred_home = pred.score1
            pred_away = pred.score2
            actual_home = pred.home_score
            actual_away = pred.away_score
            
            # Home bias - do you favor home teams too much?
            if pred_home > pred_away:
                patterns['home_bias'] += 1
            
            # Draw tendency
            if pred_home == pred_away:
                patterns['draw_tendency'] += 1
            
            # High scoring tendency
            if (pred_home + pred_away) > 3:
                patterns['high_scoring_tendency'] += 1
            
            # Conservative tendency (predicting low scores)
            if (pred_home + pred_away) <= 2:
                patterns['conservative_tendency'] += 1
            
            # Over-optimistic (predicting higher scores than actual)
            if actual_home is not None and actual_away is not None:
                if (pred_home + pred_away) > (actual_home + actual_away):
                    patterns['over_optimistic'] += 1
                elif (pred_home + pred_away) < (actual_home + actual_away):
                    patterns['under_pessimistic'] += 1
        
        # Convert to percentages
        percentage_patterns = {}
        for pattern, count in patterns.items():
            percentage_patterns[pattern] = round((count / total_predictions) * 100, 1)
        
        # Generate insights
        insights = []
        if percentage_patterns['home_bias'] > 60:
            insights.append("You tend to favor home teams - consider away team strengths more")
        if percentage_patterns['draw_tendency'] > 25:
            insights.append("You predict draws frequently - this can be risky but rewarding")
        if percentage_patterns['over_optimistic'] > 60:
            insights.append("You tend to predict higher scores than actual results")
        if percentage_patterns['conservative_tendency'] > 50:
            insights.append("You often predict low-scoring games - good for defensive matchups")
        
        return {
            'patterns': percentage_patterns,
            'insights': insights,
            'total_predictions_analyzed': total_predictions
        }
    
    async def _calculate_streaks(self, user_id: int, season: str, current_week: int) -> Dict:
        """Calculate current hot/cold streaks"""
        
        # Get recent predictions in chronological order
        recent_predictions = self.db.query(
            UserPrediction.week,
            UserPrediction.points
        ).filter(
            UserPrediction.user_id == user_id,
            UserPrediction.season == season,
            UserPrediction.week < current_week,
            UserPrediction.prediction_status == PredictionStatus.PROCESSED
        ).order_by(UserPrediction.week.desc(), UserPrediction.created.desc()).limit(20).all()
        
        if not recent_predictions:
            return {'insufficient_data': True}
        
        # Calculate current streaks
        current_hot_streak = 0
        current_cold_streak = 0
        current_perfect_streak = 0
        
        for pred in recent_predictions:
            if pred.points >= 1:  # Correct prediction
                current_hot_streak += 1
                current_cold_streak = 0
                if pred.points == 3:
                    current_perfect_streak += 1
                else:
                    current_perfect_streak = 0
            else:  # Incorrect prediction
                current_cold_streak += 1
                current_hot_streak = 0
                current_perfect_streak = 0
        
        # Update streak records in database
        await self._update_streak_records(user_id, season, current_hot_streak, current_cold_streak, current_perfect_streak)
        
        return {
            'current_hot_streak': current_hot_streak,
            'current_cold_streak': current_cold_streak,
            'current_perfect_streak': current_perfect_streak,
            'streak_status': self._get_streak_status(current_hot_streak, current_cold_streak)
        }
    
    def _get_streak_status(self, hot_streak: int, cold_streak: int) -> str:
        """Determine current streak status"""
        if hot_streak >= 5:
            return "on_fire"
        elif hot_streak >= 3:
            return "hot"
        elif cold_streak >= 5:
            return "ice_cold"
        elif cold_streak >= 3:
            return "cold"
        else:
            return "neutral"
    
    async def _update_streak_records(self, user_id: int, season: str, hot: int, cold: int, perfect: int):
        """Update user streak records"""
        
        streak_types = [
            ('hot', hot),
            ('cold', cold),
            ('perfect', perfect)
        ]
        
        for streak_type, current_count in streak_types:
            # Get or create streak record
            streak_record = self.db.query(UserStreak).filter(
                UserStreak.user_id == user_id,
                UserStreak.season == season,
                UserStreak.streak_type == streak_type
            ).first()
            
            if not streak_record:
                streak_record = UserStreak(
                    user_id=user_id,
                    season=season,
                    streak_type=streak_type,
                    current_count=current_count,
                    max_count=current_count,
                    last_updated=datetime.now(timezone.utc)
                )
                self.db.add(streak_record)
            else:
                streak_record.current_count = current_count
                streak_record.max_count = max(streak_record.max_count, current_count)
                streak_record.last_updated = datetime.now(timezone.utc)
        
        self.db.commit()
    
    async def _generate_summary(self, user_id: int, season: str, current_week: int) -> Dict:
        """Generate overall analytics summary"""
        
        # Get overall stats
        overall_stats = self.db.query(
            func.count(UserPrediction.id).label('total_predictions'),
            func.sum(UserPrediction.points).label('total_points'),
            func.sum(case((UserPrediction.points == 3, 1), else_=0)).label('perfect_predictions'),
            func.sum(case((UserPrediction.points == 1, 1), else_=0)).label('correct_results'),
            func.sum(case((UserPrediction.points == 0, 1), else_=0)).label('incorrect_predictions')
        ).filter(
            UserPrediction.user_id == user_id,
            UserPrediction.season == season,
            UserPrediction.week < current_week,
            UserPrediction.prediction_status == PredictionStatus.PROCESSED
        ).first()
        
        if not overall_stats.total_predictions:
            return {'insufficient_data': True}
        
        total_preds = overall_stats.total_predictions
        correct_preds = overall_stats.perfect_predictions + overall_stats.correct_results
        accuracy = round((correct_preds / total_preds) * 100, 1)
        avg_points = round(overall_stats.total_points / total_preds, 2)
        
        # Determine user level
        if accuracy >= 70:
            skill_level = "expert"
        elif accuracy >= 60:
            skill_level = "advanced"
        elif accuracy >= 50:
            skill_level = "intermediate"
        else:
            skill_level = "developing"
        
        return {
            'total_predictions': total_preds,
            'total_points': overall_stats.total_points,
            'accuracy_percentage': accuracy,
            'average_points': avg_points,
            'perfect_predictions': overall_stats.perfect_predictions,
            'correct_results': overall_stats.correct_results,
            'incorrect_predictions': overall_stats.incorrect_predictions,
            'skill_level': skill_level
        }
    
    async def _store_analytics(self, user_id: int, analysis_type: str, season: str, data: Dict):
        """Store analytics in database for historical tracking"""
        
        try:
            # Delete old analytics for this type/period
            self.db.query(UserAnalytics).filter(
                UserAnalytics.user_id == user_id,
                UserAnalytics.analysis_type == analysis_type,
                UserAnalytics.period == season
            ).delete()
            
            # Create new analytics record
            analytics_record = UserAnalytics(
                user_id=user_id,
                analysis_type=analysis_type,
                period=season,
                data=data,
                created_at=datetime.now(timezone.utc),
                updated_at=datetime.now(timezone.utc)
            )
            
            self.db.add(analytics_record)
            self.db.commit()
            
        except Exception as e:
            logger.error(f"Error storing analytics: {e}")
            self.db.rollback()
    
    async def generate_group_heatmap(self, group_id: int, week: int, season: str) -> Dict:
        """Generate simple consensus heatmap for a group"""
        
        logger.info(f"üî• Generating heatmap for group {group_id}, week {week}")
        
        try:
            # Check cache first
            cache_key = f"group_heatmap:{group_id}:{week}:{season}"
            if self.cache:
                cached = await self.cache.get(cache_key)
                if cached:
                    logger.info(f"üìã Returning cached heatmap for group {group_id}")
                    return cached
            
            # Get all group members' predictions for the week
            group_members = await get_group_members(self.db, group_id)
            member_ids = [m['user_id'] for m in group_members if m.get('status') == 'APPROVED']
            
            if not member_ids:
                return {'error': 'No group members found'}
            
            # Get all predictions for this week with fixture data
            predictions_data = self.db.query(
                UserPrediction.score1,
                UserPrediction.score2,
                UserPrediction.user_id,
                Fixture.fixture_id,
                Fixture.home_team,
                Fixture.away_team,
                Fixture.home_score,
                Fixture.away_score,
                Fixture.status
            ).join(
                Fixture, UserPrediction.fixture_id == Fixture.fixture_id
            ).filter(
                UserPrediction.user_id.in_(member_ids),
                UserPrediction.week == week,
                UserPrediction.season == season,
                UserPrediction.prediction_status.in_([PredictionStatus.PROCESSED, PredictionStatus.LOCKED])
            ).all()
            
            # Group by fixture
            fixture_heatmaps = defaultdict(lambda: {
                'predictions': defaultdict(int),
                'fixture_info': None,
                'total_predictions': 0
            })
            
            for pred in predictions_data:
                fixture_id = pred.fixture_id
                score_prediction = f"{pred.score1}-{pred.score2}"
                
                fixture_heatmaps[fixture_id]['predictions'][score_prediction] += 1
                fixture_heatmaps[fixture_id]['total_predictions'] += 1
                
                if not fixture_heatmaps[fixture_id]['fixture_info']:
                    fixture_heatmaps[fixture_id]['fixture_info'] = {
                        'home_team': pred.home_team,
                        'away_team': pred.away_team,
                        'actual_score': f"{pred.home_score}-{pred.away_score}" if pred.home_score is not None else None,
                        'status': pred.status.value if pred.status else None
                    }
            
            # Convert to heatmap format
            heatmaps = []
            total_accuracy = 0
            matches_with_results = 0
            
            for fixture_id, data in fixture_heatmaps.items():
                if data['total_predictions'] == 0:
                    continue
                
                # Sort predictions by frequency
                sorted_predictions = sorted(
                    data['predictions'].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )
                
                # Calculate percentages and create simple heatmap
                prediction_breakdown = []
                for score, count in sorted_predictions[:4]:  # Top 4 predictions
                    percentage = round((count / data['total_predictions']) * 100, 1)
                    is_correct = (score == data['fixture_info']['actual_score'])
                    
                    prediction_breakdown.append({
                        'score': score,
                        'count': count,
                        'percentage': percentage,
                        'is_correct': is_correct
                    })
                
                # Check if group got it right
                consensus_correct = False
                if data['fixture_info']['actual_score']:
                    actual_score = data['fixture_info']['actual_score']
                    most_popular = sorted_predictions[0][0] if sorted_predictions else None
                    consensus_correct = (most_popular == actual_score)
                    
                    if consensus_correct:
                        total_accuracy += 1
                    matches_with_results += 1
                
                heatmaps.append({
                    'fixture_id': fixture_id,
                    'match': f"{data['fixture_info']['home_team']} vs {data['fixture_info']['away_team']}",
                    'predictions': prediction_breakdown,
                    'total_predictions': data['total_predictions'],
                    'actual_result': data['fixture_info']['actual_score'],
                    'consensus_correct': consensus_correct,
                    'match_status': data['fixture_info']['status']
                })
            
            # Calculate overall group accuracy
            group_accuracy = 0
            if matches_with_results > 0:
                group_accuracy = round((total_accuracy / matches_with_results) * 100, 1)
            
            heatmap_result = {
                'group_id': group_id,
                'week': week,
                'season': season,
                'heatmaps': heatmaps,
                'group_accuracy': group_accuracy,
                'total_matches': len(heatmaps),
                'matches_completed': matches_with_results,
                'generated_at': datetime.now(timezone.utc).isoformat()
            }
            
            # Cache the result
            if self.cache:
                await self.cache.set(cache_key, heatmap_result, expiry=1800)  # 30 minute cache
            
            # Store in database
            await self._store_group_heatmap(group_id, week, season, heatmap_result)
            
            logger.info(f"‚úÖ Generated heatmap for group {group_id}: {len(heatmaps)} matches, {group_accuracy}% accuracy")
            return heatmap_result
            
        except Exception as e:
            logger.error(f"‚ùå Error generating heatmap for group {group_id}: {e}")
            raise
    
    async def _store_group_heatmap(self, group_id: int, week: int, season: str, heatmap_data: Dict):
        """Store group heatmap in database"""
        
        try:
            # Delete old heatmap for this week
            self.db.query(GroupHeatmap).filter(
                GroupHeatmap.group_id == group_id,
                GroupHeatmap.week == week,
                GroupHeatmap.season == season
            ).delete()
            
            # Create new heatmap record
            heatmap_record = GroupHeatmap(
                group_id=group_id,
                week=week,
                season=season,
                match_data=heatmap_data,
                consensus_accuracy=heatmap_data.get('group_accuracy', 0),
                created_at=datetime.now(timezone.utc),
                updated_at=datetime.now(timezone.utc)
            )
            
            self.db.add(heatmap_record)
            self.db.commit()
            
        except Exception as e:
            logger.error(f"Error storing group heatmap: {e}")
            self.db.rollback()
    
    async def invalidate_analytics_cache(self, user_id: int, season: str = None):
        """Invalidate cached analytics for a user"""
        
        if not self.cache:
            return
        
        try:
            if season:
                # Invalidate specific season
                pattern = f"user_analytics:{user_id}:{season}:*"
            else:
                # Invalidate all analytics for user
                pattern = f"user_analytics:{user_id}:*"
            
            # Note: This is a simplified approach. In production, you'd want to implement
            # a more sophisticated cache invalidation strategy
            logger.info(f"üóëÔ∏è Invalidated analytics cache for user {user_id}")
            
        except Exception as e:
            logger.error(f"Error invalidating analytics cache: {e}")